{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import variables, functions, and construct file structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T07:00:37.643879Z",
     "start_time": "2023-06-13T07:00:35.907420Z"
    }
   },
   "outputs": [],
   "source": [
    "from resource_manager import get_data_from_source\n",
    "from environment import output_path\n",
    "from functions import separate_vocal, convert_ncm, apply_so_vits, fuse_vocal_and_instrumental, Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T07:00:37.646399Z",
     "start_time": "2023-06-13T07:00:37.645104Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SONG_PATH = Path(\"./demo_assets/minstrel_short.mp3\")\n",
    "OUT_PATH = output_path.joinpath(SONG_PATH.name.rsplit('.')[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the model from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T07:01:01.817544Z",
     "start_time": "2023-06-13T07:00:42.676507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading:  kaze-mio/so-vits-genshin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a809c8a445b3452aa18e04c46e484428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 28 files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded:  kaze-mio/so-vits-genshin\n",
      "downloading:  megaaziib/hololivemix-so-vits-svc-4.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f644e8f3beb4286a56b95c5fc6b4b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded:  megaaziib/hololivemix-so-vits-svc-4.0\n",
      "hdemucs_mmi.yaml already exists, skipping\n",
      "75fc33f5-1941ce65.th already exists, skipping\n",
      "genshin: yaoyao/yaoyao_D_20000.pth\n",
      "genshin: yaoyao/yaoyao_G_20000.pth\n",
      "genshin: yaoyao/yaoyao.json\n",
      "genshin: yaoyao/yaoyao_kmeans_10000.pt\n",
      "genshin: hutao/hutao.json\n",
      "genshin: hutao/hutao_kmeans_10000.pt\n",
      "genshin: hutao/hutao_D_40000.pth\n",
      "genshin: hutao/hutao_G_40000.pth\n",
      "genshin: hutao-jp/hutao.json\n",
      "genshin: hutao-jp/hutao_jp_D_40000.pth\n",
      "genshin: hutao-jp/hutao_jp_G_40000.pth\n",
      "genshin: hutao-jp/hutao_jp_kmeans_10000.pt\n",
      "genshin: klee-jp/klee_jp_G_40000.pth\n",
      "genshin: klee-jp/klee_jp_kmeans_10000.pt\n",
      "genshin: klee-jp/klee_jp_D_40000.pth\n",
      "genshin: klee-jp/klee.json\n",
      "genshin: klee/klee_G_40000.pth\n",
      "genshin: klee/klee_D_40000.pth\n",
      "genshin: klee/klee.json\n",
      "genshin: klee/klee_kmeans_10000.pt\n",
      "genshin: nahida-jp/nahida_jp_kmeans_10000.pt\n",
      "genshin: nahida-jp/nahida_jp_D_40000.pth\n",
      "genshin: nahida-jp/nahida_jp_G_40000.pth\n",
      "genshin: nahida-jp/nahida.json\n",
      "genshin: nahida/nahida_kmeans_10000.pt\n",
      "genshin: nahida/nahida_D_40000.pth\n",
      "genshin: nahida/nahida_G_40000.pth\n",
      "genshin: nahida/nahida.json\n",
      "hololive: Pekora/config.json\n",
      "hololive: Pekora/G_26400.pth\n",
      "hololive: Kobo/config.json\n",
      "hololive: Kobo/G_17600.pth\n",
      "hololive: Moona/config.json\n",
      "hololive: Moona/G_29600.pth\n",
      "hololive: Kaela/G_8000.pth\n",
      "hololive: Kaela/config.json\n",
      "hololive: Zeta/config.json\n",
      "hololive: Zeta/G_28800.pth\n",
      "hololive: Korone/config.json\n",
      "hololive: Korone/G_480.pth\n",
      "hololive: Anya/config.json\n",
      "hololive: Anya/G_2850.pth\n",
      "hololive: Reine/G_8800.pth\n",
      "hololive: Reine/config.json\n",
      "hololive: Reine/kmeans.pt\n"
     ]
    }
   ],
   "source": [
    "model_so_vits_genshin = get_data_from_source(\"so-vits\", \"model\", \"genshin\", update_cache=False)\n",
    "model_so_vits_hololive = get_data_from_source(\"so-vits\", \"model\", \"hololive\", update_cache=False)\n",
    "model_demucs = get_data_from_source(\"demucs\", \"model\", \"hdemucs_mmi\", update_cache=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Convert .ncm file to .wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-13T07:00:38.827823Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "converted_path = convert_ncm(SONG_PATH, OUT_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate vocal and instrumental with demucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-13T07:00:38.828651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
      "Separated tracks will be stored in /home/ayano/projects/vocal_generating_pack/src/vocalinferencegui/resources/files/output/minstrel_short/hdemucs_mmi\n",
      "Separating track /home/ayano/projects/vocal_generating_pack/src/vocalinferencegui/backend/demo_assets/minstrel_short.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 93.75/93.75 [00:02<00:00, 46.14seconds/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocal': PosixPath('/home/ayano/projects/vocal_generating_pack/src/vocalinferencegui/resources/files/output/minstrel_short/hdemucs_mmi/minstrel_short/vocals.wav'), 'instrumental': PosixPath('/home/ayano/projects/vocal_generating_pack/src/vocalinferencegui/resources/files/output/minstrel_short/hdemucs_mmi/minstrel_short/no_vocals.wav')}\n"
     ]
    }
   ],
   "source": [
    "separated_path = separate_vocal(Path(converted_path), OUT_PATH)\n",
    "print(separated_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use so-vits-svc to process audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-13T07:00:38.829795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model path:  /home/ayano/projects/vocal_generating_pack/src/vocalinferencegui/resources/files/models/so-vits/yuuka/G_97600.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at lengyue233/content-vec-best were not used when initializing HubertModelWithFinalProj: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing HubertModelWithFinalProj from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertModelWithFinalProj from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertModelWithFinalProj were not initialized from the model checkpoint at lengyue233/content-vec-best and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[22:49:58] Decoder type: hifi-gan\n",
      "[22:49:59] Loaded checkpoint '/home/ayano/projects/vocal_generating_pack/src/vocalinferencegui/resources/files/models/so-vits/yuuka/G_97600.pth' (epoch 4057)\n",
      "[22:49:59] Chunk: Chunk(Speech: False, 44100.0)\n",
      "[22:49:59] Chunk: Chunk(Speech: True, 979020.0)\n",
      "[22:49:59] F0 inference time:       0.309s, RTF: 0.013\n",
      "[22:49:59] HuBERT inference time  : 0.007s, RTF: 0.000\n",
      "[22:49:59] Inference time: 0.10s, RTF: 0.00\n",
      "[22:50:00] Chunk: Chunk(Speech: False, 414540.0)\n",
      "[22:50:00] Chunk: Chunk(Speech: True, 26460.0)\n",
      "[22:50:00] F0 inference time:       0.027s, RTF: 0.017\n",
      "[22:50:00] HuBERT inference time  : 0.007s, RTF: 0.004\n",
      "[22:50:00] Inference time: 0.02s, RTF: 0.01\n",
      "[22:50:00] Chunk: Chunk(Speech: False, 273420.0)\n",
      "[22:50:00] Chunk: Chunk(Speech: True, 1764000.0)\n",
      "[22:50:01] F0 inference time:       0.610s, RTF: 0.015\n",
      "[22:50:01] HuBERT inference time  : 0.007s, RTF: 0.000\n",
      "[22:50:01] Inference time: 0.21s, RTF: 0.01\n",
      "[22:50:03] Chunk: Chunk(Speech: True, 590940.0)\n",
      "[22:50:03] F0 inference time:       0.260s, RTF: 0.018\n",
      "[22:50:03] HuBERT inference time  : 0.007s, RTF: 0.000\n",
      "[22:50:03] Inference time: 0.05s, RTF: 0.00\n",
      "[22:50:03] Chunk: Chunk(Speech: False, 20160.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ayano/projects/vocal_generating_pack/src/vocalinferencegui/resources/files/output/minstrel_short/voice_generated_with_yuuka.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "counterfeited_path = apply_so_vits(separated_path[\"vocal\"], output_path=OUT_PATH, model_path=model_so_vits_genshin[\"hutao-jp/hutao_jp_G_40000.pth\"], cluster=model_so_vits_genshin[\"hutao-jp/hutao_jp_kmeans_10000.pt\"], config_file_path=model_so_vits_genshin[\"hutao-jp/hutao.json\"], auto_predict_f0=False, speaker=\"hutao\", db_threshold=0, chunk_seconds=40)\n",
    "\n",
    "\n",
    "print(counterfeited_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-13T07:00:38.830559Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "output file: /home/ayano/projects/vocal_generating_pack/src/vocalinferencegui/resources/files/output/minstrel_short/voice_generated_with_yuuka_counterfeited_from_hutao.wav\n"
     ]
    }
   ],
   "source": [
    "output = fuse_vocal_and_instrumental(vocal_path=counterfeited_path, instrumental_path=separated_path[\"instrumental\"], output_path=OUT_PATH, speaker=\"yuuka\")\n",
    "print(\"output file:\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vocal_generating_pack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
