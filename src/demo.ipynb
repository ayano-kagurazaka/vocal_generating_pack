{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入库和构建文件架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T12:00:05.710866Z",
     "start_time": "2023-06-12T12:00:03.763015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building file structures...done\n"
     ]
    }
   ],
   "source": [
    "from functions import separate_vocal, apply_so_vits, fuse_vocal_and_instrumental, convert_ncm, Path\n",
    "from resource_manager import get_data_from_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T12:00:29.441121Z",
     "start_time": "2023-06-12T12:00:29.435885Z"
    }
   },
   "outputs": [],
   "source": [
    "SONG_PATH = Path(\"./demo_assets/escape.wav\")\n",
    "OUT_PATH = Path(\"../files/output/\").joinpath(SONG_PATH.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载模型(来源huggingface, 下载可能会较慢, 请等待)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T12:00:48.439782Z",
     "start_time": "2023-06-12T12:00:32.565397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Fetching 28 files:   0%|          | 0/28 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "393b3debad7e4c33b5e0ca7e9631148e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading hdemucs_mmi.yaml (33 bytes)\n",
      "hdemucs_mmi.yaml downloaded\n",
      "Downloading 75fc33f5-1941ce65.th (167407275 bytes)\n",
      "75fc33f5-1941ce65.th downloaded\n"
     ]
    }
   ],
   "source": [
    "model_so_vits = get_data_from_source(\"so-vits\", \"model\", \"genshin\", update_cache=True)\n",
    "model_demucs = get_data_from_source(\"demucs\", \"model\", \"hdemucs_mmi\", update_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用demucs分离音频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T12:04:31.540746Z",
     "start_time": "2023-06-12T12:02:31.981162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
      "Separated tracks will be stored in /Users/ayano/Documents/developing/AI/song_generating_pack/files/output/escape.wav\n",
      "Separating track /Users/ayano/Documents/developing/AI/song_generating_pack/src/demo_assets/escape.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 337.5/337.5 [01:09<00:00,  4.87seconds/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting file to mp3...\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File '/Users/ayano/Documents/developing/AI/song_generating_pack/files/output/escape.wav/vocals.mp3' already exists. Overwrite? [y/N] "
     ]
    }
   ],
   "source": [
    "separated_path = separate_vocal(SONG_PATH, OUT_PATH)\n",
    "print(separated_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用so-vits处理音频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T12:11:01.511384Z",
     "start_time": "2023-06-12T12:09:14.570735Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:09:17] /Users/ayano/anaconda3/envs/vocal_generating_pack/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "\n",
      "[20:09:17] /Users/ayano/Documents/developing/AI/song_generating_pack/src/thirdparties/so_vits_svc_fork/modules/synthesizers.py:81: UserWarning: Unused arguments: {'n_layers_q': 3, 'use_spectral_norm': False}\n",
      "  warnings.warn(f\"Unused arguments: {kwargs}\")\n",
      "\n",
      "[20:09:17] Decoder type: hifi-gan\n",
      "[20:09:18] Loaded checkpoint '/Users/ayano/Documents/developing/AI/song_generating_pack/files/models/so-vits/genshin/nahida_jp_G_40000.pth' (epoch 378)\n",
      "[20:09:18] Chunk: Chunk(Speech: True, 1764000.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44100 50.0\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:09:20] F0 inference time:       1.538s, RTF: 0.038\n",
      "[20:09:20] /Users/ayano/Documents/developing/AI/song_generating_pack/src/thirdparties/so_vits_svc_fork/utils.py:205: UserWarning: legacy_final_proj is deprecated\n",
      "  warnings.warn(\"legacy_final_proj is deprecated\")\n",
      "\n",
      "[20:09:21] HuBERT inference time  : 1.460s, RTF: 0.036\n",
      "[20:09:31] Inferece time: 10.21s, RTF: 0.25\n",
      "[20:09:31] Chunk: Chunk(Speech: True, 1764000.0)\n",
      "[20:09:32] F0 inference time:       0.523s, RTF: 0.013\n",
      "[20:09:33] HuBERT inference time  : 1.484s, RTF: 0.036\n",
      "[20:09:43] Inferece time: 10.15s, RTF: 0.25\n",
      "[20:09:43] Chunk: Chunk(Speech: True, 1764000.0)\n",
      "[20:09:44] F0 inference time:       0.513s, RTF: 0.013\n",
      "[20:09:45] HuBERT inference time  : 1.512s, RTF: 0.037\n",
      "[20:09:56] Inferece time: 10.19s, RTF: 0.25\n",
      "[20:09:56] Chunk: Chunk(Speech: True, 1764000.0)\n",
      "[20:09:56] F0 inference time:       0.512s, RTF: 0.012\n",
      "[20:09:58] HuBERT inference time  : 1.445s, RTF: 0.035\n",
      "[20:10:08] Inferece time: 10.12s, RTF: 0.25\n",
      "[20:10:08] Chunk: Chunk(Speech: True, 1764000.0)\n",
      "[20:10:08] F0 inference time:       0.566s, RTF: 0.014\n",
      "[20:10:10] HuBERT inference time  : 1.566s, RTF: 0.038\n",
      "[20:10:20] Inferece time: 10.18s, RTF: 0.25\n",
      "[20:10:20] Chunk: Chunk(Speech: True, 1764000.0)\n",
      "[20:10:21] F0 inference time:       0.479s, RTF: 0.012\n",
      "[20:10:22] HuBERT inference time  : 1.463s, RTF: 0.036\n",
      "[20:10:32] Inferece time: 9.92s, RTF: 0.24\n",
      "[20:10:32] Chunk: Chunk(Speech: True, 1764000.0)\n",
      "[20:10:32] F0 inference time:       0.511s, RTF: 0.012\n",
      "[20:10:34] HuBERT inference time  : 1.453s, RTF: 0.035\n",
      "[20:10:44] Inferece time: 9.81s, RTF: 0.24\n",
      "[20:10:44] Chunk: Chunk(Speech: True, 1764000.0)\n",
      "[20:10:44] F0 inference time:       0.504s, RTF: 0.012\n",
      "[20:10:46] HuBERT inference time  : 1.446s, RTF: 0.035\n",
      "[20:10:56] Inferece time: 9.90s, RTF: 0.24\n",
      "[20:10:56] Chunk: Chunk(Speech: True, 690048.0)\n",
      "[20:10:56] F0 inference time:       0.222s, RTF: 0.013\n",
      "[20:10:57] HuBERT inference time  : 0.504s, RTF: 0.030\n",
      "[20:11:01] Inferece time: 3.82s, RTF: 0.23\n"
     ]
    }
   ],
   "source": [
    "counterfeited_path = apply_so_vits(separated_path[\"vocal\"], output_path=OUT_PATH, model_path=model_so_vits[\"nahida_jp_G_40000.pth\"], config_file_path=model_so_vits[\"nahida.json\"], cluster=model_so_vits[\"nahida_jp_kmeans_10000.pt\"], auto_predict_f0=False, speaker=\"nahida\")\n",
    "print(counterfeited_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 合并"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../files/output/escape.wav/voice_generated_with_nahida_counterfeited_from_nahida.wav\n"
     ]
    }
   ],
   "source": [
    "output = fuse_vocal_and_instrumental(vocal_path=counterfeited_path, instrumental_path=separated_path[\"instrumental\"], output_path=OUT_PATH, speaker=\"nahida\")\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T12:17:36.647493Z",
     "start_time": "2023-06-12T12:17:35.958866Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-vocal_generating_pack-py",
   "language": "python",
   "display_name": "Python [conda env:vocal_generating_pack] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
